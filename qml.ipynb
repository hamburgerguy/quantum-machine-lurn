{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML: Quantum Machine Learning\n",
    "#### _Ian Convy, Ruta Jawale, James Hulett, Alex Stennet, Adam Corbo_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents the code (for Cirq 0.4.0) we used to construct and train our tree circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "import cirq\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of [1] demonstrate a method of constructing a quantum circuit that can be used to learn the handwritten digits of the MNIST dataset. One of the drawbacks of this model is that it learns the entries of arbitrary unitary matrices. This is impractical on actual quantum hardware, because the circuit would need to be recompiled after every update to the parameters. \n",
    "\n",
    "Our work explores an alternate implementation where we first decompose the unitaries as in [2] and then learn the parameters of this decomposition. Each gate in the decomposition has only one parameter, an angle of rotation, which is more feasible to update in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cirq Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our quantum circuit construction is divided into 2 categories:\n",
    "1. Image Encoding: takes an image and encodes it into a quantum circuit\n",
    "2. Tree Construction: the full tree as is described in [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a circuit which parameterizes an MNIST image using the particular pixel values in the interval $[0,1]$.\n",
    "\n",
    "These values are encoded through the following mapping:\n",
    "$$\\left|0\\right\\rangle\\mapsto\\cos \\left(\\frac{\\pi}{2}x_i\\right)\\left|0\\right\\rangle+\\sin \\left(\\frac{\\pi}{2}x_i\\right)\\left|1\\right\\rangle$$\n",
    "\n",
    "Where $x_i$ is the $i$th pixel value\n",
    "\n",
    "Of note, the gates are constructed for arbitrary image so that they can later be altered for new images without needing to recompile the entire cirtuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_gates(qubits, prefix = 'pixel'):\n",
    "    \"\"\"\n",
    "    Create parameterized Ry gates for image encoding.\n",
    "\n",
    "    Parameters:\n",
    "        qubits (seq of qubits): Qubits to encode the images\n",
    "        prefix (string): Prefix for Symbol names\n",
    "\n",
    "    Returns:\n",
    "        Sequence of gate operations on passed qubits\n",
    "    \"\"\"\n",
    "    gates = []\n",
    "    for (pos, qubit) in enumerate(qubits):\n",
    "        name = '{}_{}'.format(prefix, pos)\n",
    "        var = cirq.Symbol(name)\n",
    "        gate = cirq.YPowGate(exponent = var)\n",
    "        gates.append(gate(qubit))\n",
    "    return gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_resolver(flat_image, var_list = [], param_array = []):\n",
    "    \"\"\"\n",
    "    Create ParamResolver from a flattened image and other optional parameters.\n",
    "\n",
    "    This function creates a cirq.ParamResolver object from the pixel values of a flattened\n",
    "    image, along with any other passed names/values. This allows for reuse of the circuit\n",
    "    in different configurations.\n",
    "\n",
    "    Parameters:\n",
    "        flat_image (1-D numpy array): Array of pixel values\n",
    "        var_list (sequence): Sequence of Symbol names\n",
    "        param_array (sequence): Sequence of values to be assigned to the Symbols\n",
    "\n",
    "    Returns:\n",
    "        A ParamResolver object\n",
    "    \"\"\"\n",
    "    pixel_dict = {'pixel_{}'.format(i) : flat_image[i] for i in range(flat_image.size)}\n",
    "    param_dict = dict(zip(var_list, param_array))\n",
    "    resolver = cirq.ParamResolver({**pixel_dict, **param_dict})\n",
    "    return resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Composition\" Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates the tree structure specified in [1] in which every $2$ qubit gate is an arbitrary $4\\times 4$ unitary.\n",
    "\n",
    "The parameters of these gates are learned through the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1OqhX52_VUAk4YDV9JYfbou040VnLodAB\" alt=\"Drawing\" style=\"width:30%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use specified parameters to first construct a hermitian matrix when is then exponentiated to turn it into a unitary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unitary(gate_params):\n",
    "    \"\"\"\n",
    "    Create 4x4 unitary matrix from passed parameters.\n",
    "\n",
    "    Parameters:\n",
    "        gate_params (sequence): Sequence of real numbers to parameterize the unitary\n",
    "\n",
    "    Returns:\n",
    "        A unitary matrix array \n",
    "    \"\"\"\n",
    "    diag_params = gate_params[:4]\n",
    "    \n",
    "    upper_triangle = np.zeros([4, 4], dtype = np.complex64)\n",
    "    diag_matrix = np.diagflat(diag_params)\n",
    "    \n",
    "    off_diag_indices = [(i, j) for i in range(4) for j in range(i + 1, 4)]\n",
    "    \n",
    "    for (num, (i, j)) in enumerate(off_diag_indices):\n",
    "        upper_triangle[i, j] = gate_params[4 + num] + gate_params[10 + num]*1j\n",
    "    \n",
    "    herm_matrix = upper_triangle + (upper_triangle.T).conjugate() + diag_matrix\n",
    "    \n",
    "    (eigvalues, eigvectors) = np.linalg.eigh(herm_matrix)\n",
    "    \n",
    "    eig_exp = np.exp(eigvalues * 1j)\n",
    "    diag_exp = np.diagflat(eig_exp)\n",
    "    \n",
    "    unitary = np.einsum('bc,cd,de->be', eigvectors, diag_exp, eigvectors.T.conjugate())\n",
    "    return unitary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class contains all of the methods and attributes necessary to create and run the discriminative machine learning circuit specified in [1]. The tree must be rebuilt whenever the parameters are varied, but multiple images can be run on the same circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompTree():\n",
    "    \"\"\"\n",
    "    Circuit tree using two-qubit unitaries without decomposition.\n",
    "\n",
    "    Attributes:\n",
    "        num_pixels (integer): Number of pixels in the images\n",
    "        qubits (list of qubits): Qubits for the tree\n",
    "        image_gates (list of gate ops): Gates used to encode images\n",
    "        circuit (cirq.Circuit): Circuit for the tree\n",
    "        simulator (cirq.Simulator): Simulator for the tree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_pixels):\n",
    "        \"\"\"\n",
    "        Initialize the tree with random-normal parameters.\n",
    "\n",
    "        This method initializes the required number of qubits and the gates\n",
    "        needed for the tree. The parameters are initialized on a normal distribution,\n",
    "        and can be changed by calling 'build_tree'.\n",
    "\n",
    "        Parameters:\n",
    "            num_pixels (integer): Number of pixels in the images\n",
    "        \"\"\"\n",
    "        self.num_pixels = num_pixels\n",
    "        self.qubits = [cirq.LineQubit(pixel) for pixel in range(num_pixels)]\n",
    "        self.image_gates = get_image_gates(self.qubits)\n",
    "        num_params = (num_pixels - 1) * 16\n",
    "        initial_params = np.random.normal(size = num_params)\n",
    "        self.build_tree(initial_params)\n",
    "        self.simulator = cirq.Simulator()\n",
    "\n",
    "    def get_num_params(self):\n",
    "        return (self.num_pixels - 1) * 16\n",
    "\n",
    "    def build_tree(self, parameters):\n",
    "        \"\"\"\n",
    "        Constructs the tree circuit using the specified parameters.\n",
    "\n",
    "        This method constructs the 4x4 unitary gates needed for the tree along with\n",
    "        a measurement gate for the prediction, and then compiles the image gates, 4x4\n",
    "        gates, and measurment gate into one circuit. The two-qubits unitaries are\n",
    "        optimized on directly, so the circuit must be recreated after each iteration.\n",
    "\n",
    "        Parameters:\n",
    "            parameters (1-D numpy array): Parameters used to build the 4x4 unitaries\n",
    "        \"\"\"\n",
    "        op_size = 16\n",
    "        tree_gates = []\n",
    "        num_levels = int(np.log2(self.num_pixels))\n",
    "        param_start = 0\n",
    "        for level in range(num_levels):\n",
    "            pair_gap = 2 ** level\n",
    "            node_gap = pair_gap * 2\n",
    "            for pos in range(0, self.num_pixels, node_gap):\n",
    "                gate_params = parameters[param_start : param_start + op_size]\n",
    "                unitary = mm.build_unitary(gate_params)\n",
    "                gate = cirq.TwoQubitMatrixGate(unitary)\n",
    "                op = gate(self.qubits[pos], self.qubits[pos + pair_gap])\n",
    "                tree_gates.append(op)\n",
    "                param_start += op_size\n",
    "        self.circuit = cirq.Circuit()\n",
    "        self.circuit.append(\n",
    "            [self.image_gates, tree_gates],\n",
    "            strategy = cirq.InsertStrategy.EARLIEST)\n",
    "\n",
    "    def run(self, parameters, image_batch, reps):\n",
    "        \"\"\"\n",
    "        Runs the circuit on the image batch.\n",
    "\n",
    "        This method runs the tree circuit on each image of the batch, making the\n",
    "        specified number of measurements. It returns an array with two columns giving\n",
    "        the number of 'zeros' and 'ones' measured for each image.\n",
    "\n",
    "        Parameters:\n",
    "            image_batch (2-D array): Batch of images to be run\n",
    "            reps (integer): Number of measurments to make on each image\n",
    "            parameters: ignored input, just there to give a consistent API between tree types\n",
    "\n",
    "        Returns:\n",
    "            Array giving the results of the measurements for each image\n",
    "        \"\"\"\n",
    "        resolvers = [get_param_resolver(image.flatten()) for image in image_batch]\n",
    "        if reps:\n",
    "            measure = cirq.measure(self.qubits[0], key = 'label')\n",
    "            temp_circ = self.circuit.copy()\n",
    "            temp_circ.append([measure], strategy = cirq.InsertStrategy.EARLIEST)\n",
    "            results = self.simulator.run_sweep(\n",
    "                temp_circ,\n",
    "                params = resolvers,\n",
    "                repetitions = reps)\n",
    "            measure_counts = []\n",
    "            for result in results:\n",
    "                histo = result.histogram(key = 'label')\n",
    "                count = [histo[0], histo[1]]\n",
    "                measure_counts.append(count)\n",
    "            probs = np.array(measure_counts) / reps\n",
    "        else:\n",
    "            results = self.simulator.simulate_sweep(\n",
    "                self.circuit,\n",
    "                params = resolvers,\n",
    "                initial_state=0)\n",
    "            probs = np.array([result.density_matrix([0]).diagonal().real for result in results])\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decomposition Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaces the arbitrary $4\\times 4$ unitary matrix from [1] as a decomposition of $Z$, $Y$, and $CNOT$ gates through the process specified in [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://drive.google.com/uc?export=view&id=1ZzG1uve0m1UDXMu8aTd597GypTIdNG-l\" alt=\"Drawing\" style=\"width:100%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the ZY decomposition to represent an arbitrary single qubit unitary as a parametrized Z-Y-Z gate sequence. The names of the cirq.Symbol objects for the parameters are added to the passed variable list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zy_decomp(name, qubit, var_list):\n",
    "    \"\"\"\n",
    "    Get parameterized Z-Y-Z gate operation sequence.\n",
    "\n",
    "    Parameters:\n",
    "        name (string): Label for the 'Symbol' objects\n",
    "        qubit (cirq qubit): Qubit to be acted on\n",
    "        var_list (list): List to add Symbol names\n",
    "\n",
    "    Returns:\n",
    "        List of gate operations on the passed qubit for the decomposition\n",
    "    \"\"\"\n",
    "    z1_var = cirq.Symbol(name + '_z1')\n",
    "    var_list.append(name + '_z1')\n",
    "    z1 = cirq.ZPowGate(exponent = z1_var)\n",
    "    y1_var = cirq.Symbol(name + '_y1')\n",
    "    var_list.append(name + '_y1')\n",
    "    y1 = cirq.YPowGate(exponent = y1_var)\n",
    "    z2_var = cirq.Symbol(name + '_z2')\n",
    "    var_list.append(name + '_z2')\n",
    "    z2 = cirq.ZPowGate(exponent = z2_var)\n",
    "    return [z1(qubit), y1(qubit), z2(qubit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses the extended Cartan decomposition described in [arXiv:quant-ph/0307177](https://arxiv.org/abs/quant-ph/0307177) to represent an arbitrary two-qubit gate as a sequence of single-qubit unitaries and CNOT gates. These unitaries are then further decomposed using the ZY decomposition into gates that are implementable on actual quantum hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_decomp(name, qubit_pair, var_list):\n",
    "    \"\"\"\n",
    "    Get parameterized gate sequence for two-qubit node.\n",
    "\n",
    "    Parameters:\n",
    "        name (string): Label for the \"Symbol\" objects\n",
    "        qubit_pair (sequence): Sequence of two qubits to act on\n",
    "        var_list (list): List to add Symbol names\n",
    "\n",
    "    Returns:\n",
    "        List of gates that represent the two-qubit node\n",
    "    \"\"\"\n",
    "    (q1, q2) = qubit_pair\n",
    "    gates = []\n",
    "    u1 = zy_decomp(name + \"_u1\", q1, var_list)\n",
    "    v1 = zy_decomp(name + \"_v1\", q2, var_list)\n",
    "    gates.append([u1, v1])\n",
    "    cnot1 = cirq.CNOT(q1, q2)\n",
    "    gates.append(cnot1)\n",
    "    u2 = zy_decomp(name + \"_u2\", q1, var_list)\n",
    "    v2 = zy_decomp(name + \"_v2\", q2, var_list)\n",
    "    gates.append([u2, v2])\n",
    "    cnot2 = cirq.CNOT(q1, q2)\n",
    "    gates.append(cnot2)\n",
    "    u3 = zy_decomp(name + \"_u3\", q1, var_list)\n",
    "    v3 = zy_decomp(name + \"_v3\", q2, var_list)\n",
    "    gates.append([u3, v3])\n",
    "    cnot3 = cirq.CNOT(q1, q2)\n",
    "    gates.append(cnot3)\n",
    "    u4 = zy_decomp(name + \"_u4\", q1, var_list)\n",
    "    v4 = zy_decomp(name + \"_v4\", q2, var_list)\n",
    "    gates.append([u4, v4])\n",
    "    return gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class contains all of the methods and attributes necessary to create and run the discriminative machine learning circuit using decompositions instead of full unitaries. The circuit only needs to be compiled once, with optimization done using Symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecompTree():\n",
    "    \"\"\"\n",
    "    Circuit tree made using universal gate set.\n",
    "\n",
    "    Attributes:\n",
    "        num_pixels (integer): Number of pixels in the images\n",
    "        qubits (list of qubits): Qubits for the tree\n",
    "        image_gates (list of gate ops): Gates used to encode images\n",
    "        var_list (list): Symbol names used in the circuit\n",
    "        circuit (cirq.Circuit): Circuit for the tree\n",
    "        simulator (cirq.Simulator): Simulator for the tree\n",
    "    \"\"\"\n",
    "    def __init__(self, num_pixels):\n",
    "        \"\"\"\n",
    "        Initialized and compile the tree.\n",
    "\n",
    "        This methon initializes the qubits and the simulator and then builds the tree\n",
    "        by calling 'build_tree'.\n",
    "\n",
    "        Parameters:\n",
    "            num_pixels (integer): Number of pixels in the images\n",
    "        \"\"\"\n",
    "        self.num_pixels = num_pixels\n",
    "        self.qubits = [cirq.LineQubit(pixel) for pixel in range(num_pixels)]\n",
    "        self.build_perm()\n",
    "        self.simulator = cirq.Simulator()\n",
    "\n",
    "    def get_num_params(self):\n",
    "        return len(self.var_list)\n",
    "\n",
    "    def build_perm(self):\n",
    "        \"\"\"\n",
    "        Construct the parameterized gate operations for the tree.\n",
    "\n",
    "        This method constructs the image gates and node decomposition gates needed for\n",
    "        the tree, along with a measurement gate for the prediction, and then compiles the\n",
    "        gates into one circuit. The gates are all parameterized using Symbols, so the\n",
    "        circuit only needs to be compiled once.\n",
    "\n",
    "        parameters is not used, and is only there to give a consistent API\n",
    "        \"\"\"\n",
    "        self.image_gates = get_image_gates(self.qubits)\n",
    "        tree_gates = []\n",
    "        self.var_list = []\n",
    "        num_levels = int(np.log2(self.num_pixels))\n",
    "        for level in range(num_levels):\n",
    "            pair_gap = 2 ** level\n",
    "            node_gap = pair_gap * 2\n",
    "            for pos in range(0, self.num_pixels, node_gap):\n",
    "                name = '{}_{}'.format(level, pos)\n",
    "                qubit_pair = [self.qubits[pos], self.qubits[pos + pair_gap]]\n",
    "                node_gates = mm.node_decomp(name, qubit_pair, self.var_list)\n",
    "                tree_gates.append(node_gates)\n",
    "        self.circuit = cirq.Circuit()\n",
    "        self.circuit.append(\n",
    "            [self.image_gates, tree_gates],\n",
    "            strategy = cirq.InsertStrategy.EARLIEST)\n",
    "\n",
    "    def build_tree(self, parameters):\n",
    "        pass\n",
    "\n",
    "    def run(self, parameters, image_batch, reps):\n",
    "        \"\"\"\n",
    "        Runs the circuit on the image batch using the specified parameters.\n",
    "\n",
    "        This method runs the tree circuit on each image of the batch, making the\n",
    "        specified number of measurements. It returns an array with two columns giving\n",
    "        the number of 'zeros' and 'ones' measured for each image.\n",
    "\n",
    "        Parameters:\n",
    "            parameters (1-D array): Parameters used for the decomposition gates\n",
    "            image_batch (2-D array): Batch of images to be run\n",
    "            reps (integer): Number of measurments to make on each image\n",
    "\n",
    "        Returns:\n",
    "            Array giving the results of the measurements for each image\n",
    "        \"\"\"\n",
    "        resolvers = [get_param_resolver(image.flatten(), self.var_list, parameters) for image in image_batch]\n",
    "        if reps:\n",
    "            measure = cirq.measure(self.qubits[0], key = 'label')\n",
    "            temp_circ = self.circuit.copy()\n",
    "            temp_circ.append([measure], strategy = cirq.InsertStrategy.EARLIEST)\n",
    "            results = self.simulator.run_sweep(\n",
    "                temp_circ,\n",
    "                params = resolvers,\n",
    "                repetitions = reps)\n",
    "            measure_counts = []\n",
    "            for result in results:\n",
    "                histo = result.histogram(key = 'label')\n",
    "                count = [histo[0], histo[1]]\n",
    "                measure_counts.append(count)\n",
    "            probs = np.array(measure_counts) / reps\n",
    "        else:\n",
    "            results = self.simulator.simulate_sweep(\n",
    "                self.circuit,\n",
    "                params = resolvers,\n",
    "                initial_state=0)\n",
    "            probs = np.array([result.density_matrix([0]).diagonal().real for result in results])\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Keras's built in MNIST dataset as our training and testing set.\n",
    "\n",
    "Since we need a qubit for every pixel and have limited processing power, we scale each MNIST image to $4\\times 4$. This is an acceptable downsampling size as it has been shown in standard learning practices that it is still possible to achieve a high accuracy on these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(keep_labels=[0,1]):\n",
    "    mnist_data = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    train_images = mnist_data[0][0]\n",
    "    train_labels = mnist_data[0][1]\n",
    "    test_images  = mnist_data[1][0]\n",
    "    test_labels  = mnist_data[1][1]\n",
    "\n",
    "    subset_train = []\n",
    "    for index in range(len(train_labels)):\n",
    "        if train_labels[index] not in keep_labels:\n",
    "            subset_train.append(index)\n",
    "    subset_train_images = np.delete(train_images, subset_train, 0)\n",
    "    subset_train_labels = np.delete(train_labels, subset_train, 0)\n",
    "\n",
    "    subset_test = []\n",
    "    for index in range(len(test_labels)):\n",
    "        if test_labels[index] not in keep_labels:\n",
    "            subset_test.append(index)\n",
    "    subset_test_images = np.delete(test_images, subset_test, 0)\n",
    "    subset_test_labels = np.delete(test_labels, subset_test, 0)\n",
    "\n",
    "    return subset_train_images, subset_train_labels, subset_test_images, subset_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, shape):\n",
    "    num_images = images.shape[0]\n",
    "    new_images_shape = (num_images, shape[0], shape[1])\n",
    "    new_images = skimage.transform.resize(\n",
    "        images,\n",
    "        new_images_shape,\n",
    "        anti_aliasing = True,\n",
    "        mode = 'constant')\n",
    "    return new_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike ordinary machine learning algorithms, is isn't possible to exactly extract out the probabilities of a particular output using any physical means; instead, this would need to be done empirically via sampling many times. \n",
    "\n",
    "Because this is slow and can lead to inaccuracies in results, it also accomodates specifying no sampling (argument of 0 for `num_samples`) and instead taking advantage of the fact we are only simulating a quantum machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_empirical_probs(data, tree, tree_parameters, num_samples):\n",
    "    \"\"\"\n",
    "    Empirically finds the probability of seeing 0/1 on each data point\n",
    "\n",
    "    data: a numpy array of data points to be labeled\n",
    "    tree: an instance of CompTree or DecompTree\n",
    "    tree_parameters: a numpy array of the parameters needed to specify the tree to the classification function\n",
    "    num_samples: the number of samples to take when estimating the label.  If 0, looks at the wave function.\n",
    "\n",
    "    Returns a numpy array of dimension (len(data), 2) where ith row contains probabilities of classifying data point i as 0/1\n",
    "    \"\"\"\n",
    "    tree.build_tree(tree_parameters)\n",
    "    probs = tree.run(tree_parameters, data, num_samples)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the max loss function specified in [1]:\n",
    "$$Loss(\\Lambda, x) = \\max(p_\\text{largest false}(\\Lambda, x) - p_{l_x}(\\Lambda, x) + \\lambda, 0)^n$$\n",
    "\n",
    "$$Loss(\\Lambda) = \\frac{1}{|\\text{data}|}\\sum_{x\\in\\text{data}}Loss(\\Lambda, x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_max_loss(data, labels, tree, lmda, eta, num_samples):\n",
    "    \"\"\"\n",
    "    Create a loss function with the given hyperparameters and the data.\n",
    "\n",
    "    data: a numpy array of data points to be labeled\n",
    "    labels: numpy array of true classification labels\n",
    "    lmda: hyperparameter\n",
    "    eta: hyperparameter\n",
    "    num_samples: number of samples to take when estimating labels.  If 0, looks at wave function instead.\n",
    "\n",
    "    Returns a loss function that just takes in the parameters for the tree.\n",
    "    \"\"\"\n",
    "    assert len(labels.shape) == 1\n",
    "\n",
    "    def max_loss(tree_parameters):\n",
    "        \"\"\"\n",
    "        Computes the max loss.\n",
    "\n",
    "        tree_parameters: the current parameters to the tree\n",
    "\n",
    "        Returns the loss of our model given the input parameters.\n",
    "        \"\"\"\n",
    "        probs = find_empirical_probs(data, tree, tree_parameters, num_samples)\n",
    "        assert len(labels) == probs.shape[0]\n",
    "\n",
    "        correct_probs = probs[np.arange(len(labels)),labels]\n",
    "\n",
    "        loss = np.sum(np.clip(1 - 2 * correct_probs + lmda, 0.0, None)**eta) / len(labels)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    return max_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simultaneous perturbation stochastic approximation (SPSA) is an optimization algorithm which, given a loss function and parameters to learn, attempts to find a global minimum by using a random perturbation vector to estimate the gradient.\n",
    "\n",
    "We use this here to optimize the loss function specified in the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(curr_params, curr_velocity, loss_function, gamma, learning_rate, epsilon):\n",
    "    \"\"\"\n",
    "    Do one round of SPSA. Runs loss_function twice.\n",
    "\n",
    "    curr_params: the parameters to the tree before this round, as a numpy array\n",
    "    curr_velocity: the velocity from the last round, as a numpy array\n",
    "    loss_function: the loss function being used\n",
    "    gamma: hyperparameter controlling how quickly velocity decays\n",
    "    learning_rate: hyperparameter controlling how big our updates are\n",
    "    epsilon: hyperparameter controlling the size of the perterbation\n",
    "\n",
    "    Returns the parameters and velocity after this step, as a numpy arrays.\n",
    "    \"\"\"\n",
    "    perturbation = (2*np.round(np.random.random(len(curr_params))) - 1) * epsilon\n",
    "\n",
    "    loss_plus = loss_function(curr_params + perturbation)\n",
    "    loss_minus = loss_function(curr_params - perturbation)\n",
    "    approx_gradient = (loss_plus - loss_minus) / (2 * perturbation)\n",
    "    next_velocity = gamma * curr_velocity - learning_rate * approx_gradient\n",
    "    next_params = curr_params + next_velocity\n",
    "    return next_params, next_velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function pieces together all of the components by iterating for as many epochs as are specified and uses the loss function to update the circuit parameters on each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, train_labels, val_data, val_labels, hyper, tree_class=CompTree):\n",
    "    \"\"\"\n",
    "    Trains the model.\n",
    "\n",
    "    train_data: a numpy array (batch_size, image dimension) of training data to be classified\n",
    "    train_labels: a numpy array (batch_size) of corresponding labels\n",
    "    val_data: a numpy array (batch_size, image dimension) of validation data to be evaluated\n",
    "    val_labels: a numpy array (batch_size) of corresponding labels\n",
    "    hyper: a dictionary containing hyperparameter values.\n",
    "    tree_class: which type of tree to use.  Either CompTree or DecompTree\n",
    "\n",
    "    Returns tree parameters.\n",
    "    \"\"\"\n",
    "    # Unpack training hyperparameters\n",
    "    batch_size, num_epoch = hyper['batch_size'], hyper['num_epoch']\n",
    "    # Unpack update hyperparameters\n",
    "    a, s, A, b, t, gamma = hyper['a'], hyper['s'], hyper['A'], hyper['b'], hyper['t'], hyper['gamma']\n",
    "    # Unpack loss hyperparameters\n",
    "    lmda, eta = hyper['lmda'], hyper['eta']\n",
    "    # Unpack sampling hyperparameter\n",
    "    num_samples = hyper['num_samples']\n",
    "\n",
    "    # Initialize the params and velocity\n",
    "    num_iter = len(train_data) // batch_size\n",
    "    tree = tree_class(len(train_data[0]))\n",
    "    mu, sigma = 0, 1\n",
    "    params = np.random.normal(mu, sigma, tree.get_num_params())\n",
    "    velocity = 0\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        for i in tqdm(range(num_iter)):\n",
    "            loss_function = make_max_loss(train_data[i*batch_size:(i+1)*batch_size],\n",
    "                                          train_labels[i*batch_size:(i+1)*batch_size],\n",
    "                                          tree, lmda, eta, num_samples)\n",
    "\n",
    "            epsilon = a/(epoch+1+A)**s\n",
    "            learning_rate = b/(epoch+1)**t\n",
    "            params, velocity = update_params(params, velocity, loss_function,\n",
    "                                                    gamma, learning_rate, epsilon)\n",
    "\n",
    "        print(\"-------------\", flush=True)\n",
    "        print(\"Epoch: {}\".format(epoch), flush=True)\n",
    "        # Evaluate model\n",
    "        accuracy = evaluate_model(val_data, val_labels,\n",
    "                                  params, num_samples, tree_class)\n",
    "        print(\"Validation Accuracy: {}\".format(accuracy), flush=True)\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to calculate the accuracy of a particular model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, labels, tree_parameters, num_samples, tree_class=CompTree):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a set of data.\n",
    "\n",
    "    data: a numpy array (num images, image dimension) of data points to be labeled\n",
    "    labels: a numpy array (num images) of corresponding labels\n",
    "    tree_parameters: the parameters to build the tree with\n",
    "    num_samples: how many times we sample when estimating labels.  If 0, uses wave function instead of sampling\n",
    "    tree_class: what type of tree to use.  Either CompTree or DecompTree\n",
    "\n",
    "    Returns the percentage of data points correctly labeled.\n",
    "    \"\"\"\n",
    "    tree = tree_class(len(data[0]))\n",
    "    prediction_probs = find_empirical_probs(data, tree, tree_parameters, num_samples)\n",
    "    prediction = np.argmax(prediction_probs, axis=1)\n",
    "    return (100.0 * np.count_nonzero(prediction==labels)) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images with labels 0 and 1\n",
    "train_images, train_labels, test_images, test_labels = load_data(keep_labels=[0,1])\n",
    "\n",
    "# Split training and validation set 80/20\n",
    "len_train, len_test = len(train_labels), len(test_labels)\n",
    "len_train, len_val = len_train - int(0.2*len_train), int(0.2*len_train)\n",
    "train_images, val_images = train_images[:len_train], train_images[len_train:]\n",
    "train_labels, val_labels = train_labels[:len_train], train_labels[len_train:]\n",
    "\n",
    "# Preprocess images\n",
    "new_shape = (4,4)\n",
    "train_data = resize_images(train_images, new_shape).reshape((len_train, new_shape[0]*new_shape[1]))\n",
    "val_data = resize_images(val_images, new_shape).reshape((len_val, new_shape[0]*new_shape[1]))\n",
    "test_data = resize_images(test_images, new_shape).reshape((len_test, new_shape[0]*new_shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 different hyper parameters that contribute to the models learning in a handful of way:\n",
    "- batch size, how many images are put into a mini-batch, is controlled by `batch_size`\n",
    "- how many epochs are run is controlled by `num_epoch`\n",
    "- perterbation annealing is updated through 3 hyper parameters `a`, `A`, `s` and, given an epoch iteration `k`, is updated via the following multiplier: \n",
    "$$\\frac{a}{(k + 1 + A)^s}$$\n",
    "- learning rate annealing is updated through 2 hyper parameters `b`, `t` and, given an epoch iteration `k`, is updated via the following multiplier: \n",
    "$$\\frac{b}{(k + 1)^t}$$\n",
    "- how fact the velocity decays is controlled by `gamma`\n",
    "- the threshold for how far apart the correct / incorrect label probabilities should be is controlled by `lmda`\n",
    "- the loss is raised to an exponent which is controlable via `eta`, this allows for further specificity of how the loss function contributes (a larger exponent will make the loss smaller)\n",
    "- how many samples are used to estimate a label probability is controlled by `num_samples` (note: setting this to 0 will cause the model to use the exact wave function instead which isn't feasible on actual quantum hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select hyperparams\n",
    "hyper = {\"batch_size\": 200, \"num_epoch\": 10, \"num_samples\": 0, \"lmda\": 0.234, \"eta\": 4.59,\n",
    "         \"a\": 10.0, \"s\": 4.13, \"A\": 10, \"b\": 10.0, \"t\": 0.658, \"gamma\": 0}\n",
    "\n",
    "# Select training, validation, and test subset\n",
    "num_data = 2000\n",
    "train_data, train_labels = train_data[:num_data], train_labels[:num_data]\n",
    "val_data, val_labels = val_data[:num_data], val_labels[:num_data]\n",
    "\n",
    "# Train tree model on training dataset\n",
    "tree_parameters = train_model(train_data, train_labels, val_data, val_labels,\n",
    "                              hyper=hyper, tree_class=CompTree)\n",
    "\n",
    "# Validate tree model on training, validation, and test datasets\n",
    "train_acc = evaluate_model(train_data, train_labels, tree_parameters, hyper[\"num_samples\"])\n",
    "val_acc = evaluate_model(val_data, val_labels, tree_parameters, hyper[\"num_samples\"])\n",
    "\n",
    "print(\"Training: {}% Validation: {}%\".format(train_acc, val_acc), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] W. Huggins, P. Patel, K. B. Whaley, and E. M. Stoudenmire, Towards Quantum Machine Learning with Tensor Networks\n",
    "\n",
    "[2] Vidal, Guifre, and Christopher M. Dawson. Universal quantum circuit for two-qubit transformations with three controlled-NOT gates. Physical Review A 69.1 (2004): 010301."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
